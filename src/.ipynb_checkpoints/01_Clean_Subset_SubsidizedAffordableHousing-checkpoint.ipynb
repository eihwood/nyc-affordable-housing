{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0772f02",
   "metadata": {},
   "source": [
    "## NYU Furman Center Core Data: Subsidized Housing Database \n",
    "\n",
    "Subsidized Housing Database download package contains two data files and two corresponding data dictionary files:\n",
    "\n",
    "The FC_SHD_subsidy_analysis_yyyy-mm-dd.csv file is provided for detailed analysis of subsidies and properties. Each entry in this data file represents the combination of a subsidy record and a property. If multiple subsidies are available for one property (identified by Borough-Block-Lot aka BBL), there will be multiple entries associated with the single BBL. Also, if a single subsidy contract applies to multiple properties, then there will be multiple entries associated with the single subsidy. Along with the subsidy information such as corresponding agency, subsidy type, as well as the start and end date, the subsidy analysis file provides the information of the property including address, the number of residential units, year built and etc. The file also provides latitude and longitude points of the BBLs for potential geospatial analysis. For detailed information, please refer to FC_SHD_subsidy_analysis_data_dictionary_yyyy-mm-dd.xlsx.\n",
    "\n",
    "The FC_SHD_bbl_analysis_yyyy-mm-dd.csv file will be useful for property-level analysis. Each entry is a unique property (BBL). The data set has compiled all the subsidies associated with the BBL into one entry with the property details, captured in a series of columns for each program. The file also provides latitude and longitude points of the BBLs for potential geospatial analysis. For detailed information, please refer to FC_SHD_bbl_analysis_data_dictionary_yyyy-mm-dd.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaaa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in subsidized housing data and define the dates as strings\n",
    "data = pd.read_csv(\"../data/affordablehousing/FC_SHD_subsidy_analysis_2022-12-20.csv\", \n",
    "                   dtype={'start_date': str,\n",
    "                         'end_date': str})\n",
    "\n",
    "# Drop column of index using DataFrame.iloc[] and drop() methods.\n",
    "data = data.drop(data.iloc[:, 17:129],axis = 1)\n",
    "\n",
    "# Drop ref_address, reac_score and reac_date and change the name of ref_bbl to 'bbl' for subsequent merge\n",
    "data = data.drop(['reac_score', 'reac_date', 'ref_address'], axis =1).rename(columns = {\"ref_bbl\": 'bbl'})\n",
    "\n",
    "# Check label consistencies in categorical variable columns (e.g. preservation)\n",
    "print(data['preservation'].value_counts(dropna=False)) # issue with new construction label\n",
    "print(data['subsidy_name'].value_counts(dropna=False)) # all good\n",
    "\n",
    "print(data['sub_subsidy_name'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# Fix Issue of inconsisten naming in the \"preservation\" column\n",
    "data['preservation'] = data['preservation'].replace('New<a0>Construction', 'New Construction')\n",
    "\n",
    "# Read in subsidized housing location data for each bbl. \n",
    "locs = pd.read_csv(\"../data/affordablehousing/FC_SHD_bbl_analysis_2022-12-20.csv\",\n",
    "                  dtype = {'tract_10':str,\n",
    "                          'year_built':str,\n",
    "                          'sba_id':str})\n",
    "\n",
    "# Drop unnecessary columns\n",
    "locs = locs.drop(locs.iloc[:, 22:122], axis = 1)\n",
    "\n",
    "\n",
    "# Convert Dates\n",
    "data['end_date'] = pd.to_datetime(data['end_date'])\n",
    "\n",
    "data['start_date'] = pd.to_datetime(data['start_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643966cf",
   "metadata": {},
   "source": [
    "## Subsetting \n",
    "1. Top 10 most common subsidy programs\n",
    "2. Current subsidies\n",
    "\n",
    "Background:\n",
    "Subsidy Start and End Dates: For a given subsidy, the start date indicates when the subsidy was issued or when the property was placed in service. The end date indicates when the requirements associated with the subsidy end or expire. In cases where only the year is known, the start date is set to January 1st and the end date is set to December 31st. \n",
    "\n",
    "If a subsidy is permanent or has no foreseeable end date (e.g. Public Housing, Inclusionary Zoning), the end date is listed as blank. Program notes are as follows:\n",
    "\n",
    "Mitchell-Lama: The end date listed for Mitchell-Lama properties reflects the opt-out date. The Subsidized Housing Database includes Mitchell-Lama properties that have exceeded their opt-out date but (as best we can determine) have not opted out of the program. \n",
    "Low-Income Housing Tax Credit (LIHTC): LIHTC data is from HUD’s LIHTC Database and only includes the subsidy start date. For these properties we estimate the end date of the LIHTC subsidy to be 30 years from the start date. \n",
    "\n",
    "Therefore in order to obtain only those currently active subsidies (through Jan 1, 2023) I will subset end_dates that occur after Dec 31, 2022 or end_dates that are listed as null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBSET ONLY THE TOP 10 MOST FREQUENT SUBSIDIES\n",
    "# get top 10 for further analysis\n",
    "top10 = data['sub_subsidy_name'].value_counts().index.tolist()[0:10] # last number is not inclusive\n",
    "print(len(top10))\n",
    "print(top10)\n",
    "print(type(top10))\n",
    "\n",
    "# Subset the relevant subsidy program categories\n",
    "subset_subsidies = data[data['sub_subsidy_name'].isin(top10)]\n",
    "print(len(data))\n",
    "print(len(subset_subsidies)) # dropped 269 subsidy--bbl records from subsid\n",
    "\n",
    "\n",
    "# Subset only those active housing subsidies as of 01 JAN 2023\n",
    "import datetime as dt\n",
    "\n",
    "# create a cutoff date variable\n",
    "stop_date = dt.datetime(2022, 12, 31)\n",
    "\n",
    "# PD query\n",
    "cur_subsidies = subset_subsidies.query('end_date > @stop_date | end_date.isnull()')\n",
    "print(len(cur_subsidies))\n",
    "print(\"No. dropped records: \", len(subset_subsidies)-len(cur_subsidies))\n",
    "\n",
    "\n",
    "# Bar plot\n",
    "cur_subsidies['sub_subsidy_name'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10495359",
   "metadata": {},
   "source": [
    "## Merge \n",
    "1. the loc bbl level data with the subsidy-bbl level data on unique bbl identifier\n",
    "2. some important metadata regarding target income levels for each subsidy program \n",
    "\n",
    "\n",
    "Background:\n",
    "Properties in the Subsidized Housing Database are tax parcels, identified by a unique  borough-block-lot (BBL) number.\n",
    "\n",
    "An individual subsidy agreement may apply to more than one property. In some cases, the data we receive only lists a single address for a subsidy even though the agreement covers multiple properties. In order to identify all properties associated with a subsidy, we search New York City property records to identify the related properties. First, we convert the address listed in the subsidy agreement to its BBL using the process described above. We call this property the reference BBL. We then search New York City Department of Finance’s Automated City Register Information System (ACRIS) to identify related properties - properties that are referenced in documents associated with the reference BBL. We then cross-check information in the subsidy agreement with the property information from ACRIS to ensure the related properties are in fact associated (we match based on the number of residential units). We only allow matches to associated BBLs with a building class that falls under the following building classification codes from the Department of Finance: A, B, C, D, R, S, L, I, N, H3, H6, H7, H8, and K4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740befff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge location data with the bbl key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898a64d",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "1. Subsidies by Borough\n",
    "2. Subsidies by Program Type (sub_subsidy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb248b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of currently active subsidy-building by Borough\n",
    "#sub_boro = cur_subsidies.groupby('boro_name').size()\n",
    "#print(sub_boro)\n",
    "# Bar plot of subsidies by borough\n",
    "cur_subsidies['boro_name'].value_counts().plot(kind='bar')\n",
    "\n",
    "\n",
    "\n",
    "# Number of currently active subsidy-building by Agency\n",
    "sub_agen = cur_subsidies.groupby(['agency_name']).size()\n",
    "print(sub_agen)\n",
    "type(sub_agen)\n",
    "\n",
    "# Get building and unit counts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1003505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT WITH LOCS \n",
    "import numpy as np\n",
    "\n",
    "def get_types(row):\n",
    "    # Get the column names where the value is 1\n",
    "    cols = row.eq(1).dot(df.columns[:]+',').rstrip(',').split(',')\n",
    "    # Get the unique types depending on the first character of the columns\n",
    "    unique = np.unique([c[0:4] for c in cols])\n",
    "    # Separate in sub lists depending on the type\n",
    "    x = [[e for e in cols if e[0] == letter] for letter in unique]\n",
    "    # Remove the first element of the sub lists if it contains more than 1 element\n",
    "    # For example, if A1, A11 and A12 exist then it will drop A1 and keep A11 and A12\n",
    "    x = [e[1:] if len(e) > 1 else [e[0]] for e in x]\n",
    "    # Flatten the array\n",
    "    x = [s for e in x for s in e]\n",
    "    # Convert the rows to series and fill with nan if the length is not 4\n",
    "    # Note: the length is now a constant so you have to consider using a variable\n",
    "    #      if you need to work with more types in the future\n",
    "    x = pd.Series(np.append(np.array(x), np.repeat(np.nan, 4 - len(x))))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/affordablehousing/FC_SHD_bbl_analysis_2022-12-20.csv\")\n",
    "\n",
    "df = df.filter(regex= '^prog_*')\n",
    "\n",
    "df1 = df.apply(get_types, axis=1)\n",
    "\n",
    "df1.head()\n",
    "#df1.rename(columns={0: 'type1', 1: 'type2', 2: 'type3', 3: 'type4'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96193280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/affordablehousing/FC_SHD_bbl_analysis_2022-12-20.csv\")\n",
    "\n",
    "df_filt = df.filter(regex= '^prog_*')\n",
    "\n",
    "print(len(df.columns))\n",
    "\n",
    "# use df.dot to collapse all binary prog_* columns into one column \n",
    "subsidy = pd.DataFrame(df_filt.dot(df_filt.columns))\n",
    "\n",
    "subsidy.index.names = ['IDX']\n",
    "\n",
    "# Rename to something sensical\n",
    "subsidy = subsidy.rename(columns={0: 'subsidy_program'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8161855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now collapse the dates\n",
    "\n",
    "end_date = (df[df.filter(like='end') # Using filter to select certain columns.\n",
    "                     .columns\n",
    "                     .sort_values(ascending=False)] # Sort them descending.\n",
    "                  .bfill(axis=1) # backfill values\n",
    "                  .iloc[:,0]) # take the first column, \n",
    "                              # This has the first non-nan value.\n",
    "\n",
    "subsidy['max_end_date'] = end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00cd298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDX\n",
       "0        20301231.0\n",
       "1        20291231.0\n",
       "2        20281231.0\n",
       "3        20291231.0\n",
       "4        20381231.0\n",
       "            ...    \n",
       "13147           NaN\n",
       "13148           NaN\n",
       "13149           NaN\n",
       "13150           NaN\n",
       "13151           NaN\n",
       "Name: end_year15, Length: 13152, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecac99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
